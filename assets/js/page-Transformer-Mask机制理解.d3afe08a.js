(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{540:function(t,s,a){t.exports=a.p+"assets/img/image1.53dbb1fa.png"},541:function(t,s,a){t.exports=a.p+"assets/img/image2.fcc279c7.png"},542:function(t,s,a){t.exports=a.p+"assets/img/image3.8647d12b.png"},543:function(t,s,a){t.exports=a.p+"assets/img/image4.ae0316ae.png"},685:function(t,s,a){"use strict";a.r(s);var n=a(1),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("center",[n("img",{attrs:{src:a(540),width:"40%"}})]),t._v(" "),n("p",[t._v("图片摘自："),n("a",{attrs:{href:"https://ifwind.github.io/2021/08/17/Transformer%E7%9B%B8%E5%85%B3%E2%80%94%E2%80%94%EF%BC%887%EF%BC%89Mask%E6%9C%BA%E5%88%B6/",target:"_blank",rel:"noopener noreferrer"}},[t._v("博客文章"),n("OutboundLink")],1)]),t._v(" "),n("p",[t._v("Mask（掩码）机制经常用于NLP任务中，大致可以分为两类：")]),t._v(" "),n("p",[t._v("（1）用于处理非定长序列的Padding的Mask；去除各种Padding在训练过程中的影响。【作用Encoder】")]),t._v(" "),n("p",[t._v("（2)用于防止标签泄露的Sequence的Mask；将输入进行遮盖，避免decoder看到后面要预测的东西。【作用Decoder】")]),t._v(" "),n("h2",{attrs:{id:"padding-mask"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#padding-mask"}},[t._v("#")]),t._v(" Padding Mask")]),t._v(" "),n("p",[t._v("在NLP任务中，文本通常是不定长的，所以在输入一个样本长短不一的batch到网络前，要对batch中的样本进行truncating截断/padding补齐操作，以便能形成一个张量的形式输入网络：\n"),n("center",[n("img",{attrs:{src:a(541),width:"60%"}})]),t._v("\nMask矩阵中1代表有效数字，0代表无效字（或者使用T/F）。")],1),t._v(" "),n("p",[n("strong",[t._v("Padding Mask的生成")]),t._v("：padding补齐操作在batch输入网络前完成，并同步生成Mask矩阵。")]),t._v(" "),n("p",[n("strong",[t._v("Padding Mask的使用")]),t._v("：通常用在最终结果输出、损失函数计算等；即不需要无用的padding参与计算时。")]),t._v(" "),n("p",[n("strong",[t._v("在self-attention中的padding mask")])]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("attention")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mask"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dropout"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"Compute 'Scaled Dot Product Attention'\"")]),t._v("\n    d_k "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    scores "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transpose"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d_k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Q,K点积之后，需要先经过mask再进行softmax")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#对于要屏蔽的部分，mask之后的输出需要为负无穷（极小值），这样softmax后输出为0，避免padding的影响")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" mask "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        scores "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scores"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("masked_fill"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mask "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mask步骤，用 -1e9 代表负无穷")]),t._v("\n    p_attn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scores"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dim "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" dropout "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        p_attn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dropout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p_attn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matmul"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p_attn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" p_attn\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])]),n("h2",{attrs:{id:"sequence-mask"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sequence-mask"}},[t._v("#")]),t._v(" Sequence Mask")]),t._v(" "),n("p",[t._v("常见的应用场景是：需要一个词预测下一个词。若使用self attention或者其它使用上下文信息的机制，会导致模型“提前看到”待预测的内容。\n为不泄露要预测的标签信息，需要Mask来“遮盖”。")]),t._v(" "),n("center",[n("img",{attrs:{src:a(542),width:"60%"}})]),t._v(" "),n("h2",{attrs:{id:"bert和ernie中的mask"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#bert和ernie中的mask"}},[t._v("#")]),t._v(" BERT和ERNIE中的Mask")]),t._v(" "),n("p",[t._v("在decoder部分加入mask除防止标签泄露以外，模型利用这种填空机制可以帮助模型学习更好。如BERT和ERNIE模型中利用的Masked LM（MLM）。")]),t._v(" "),n("p",[t._v("Masked LM随机掩盖部分输入词，然后对那些被掩盖的词进行预测。在训练的过程中，BERT随机地掩盖每个序列中15％的token，并不是像word2vec中的cbow那样去对每一个词都进行预测。MLM从输入中随机地掩盖一些词，其目标是基于其上下文来预测被掩盖单词的原始词汇。")]),t._v(" "),n("p",[t._v("ERINE不是在token level进行mask操作，而是在phrase level进行mask操作。")]),t._v(" "),n("center",[n("img",{attrs:{src:a(543),width:"60%"}})]),t._v(" "),n("p",[t._v("图片摘自："),n("a",{attrs:{href:"https://ifwind.github.io/2021/08/17/Transformer%E7%9B%B8%E5%85%B3%E2%80%94%E2%80%94%EF%BC%887%EF%BC%89Mask%E6%9C%BA%E5%88%B6/",target:"_blank",rel:"noopener noreferrer"}},[t._v("博客文章"),n("OutboundLink")],1)]),t._v(" "),n("h2",{attrs:{id:"参考资料"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),n("p",[t._v("1、冬于博客——"),n("a",{attrs:{href:"https://ifwind.github.io/2021/08/17/Transformer%E7%9B%B8%E5%85%B3%E2%80%94%E2%80%94%EF%BC%887%EF%BC%89Mask%E6%9C%BA%E5%88%B6/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Transformer的Mask机制"),n("OutboundLink")],1)]),t._v(" "),n("p",[t._v("2、Transformer中的mask："),n("a",{attrs:{href:"https://blog.csdn.net/weixin_42253689/article/details/113838263",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://blog.csdn.net/weixin_42253689/article/details/113838263"),n("OutboundLink")],1)])],1)}),[],!1,null,null,null);s.default=e.exports}}]);